{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# base\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "import random\n",
    "import logging\n",
    "import IPython\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "# image processing\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "#ml\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# deep learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision.models import resnet34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python version: 3.8.1 (default, Jan  8 2020, 22:29:32) \n",
      "[GCC 7.3.0]\n",
      "SciPy version: 1.4.1\n",
      "NumPy version: 1.18.1\n",
      "scikit-learn version: 0.22.2.post1\n",
      "pandas version: 1.0.3\n",
      "matplotlib version: 3.2.1\n",
      "IPython version: 7.13.0\n",
      "OpenCV version: 4.2.0\n",
      "Torch version: 1.4.0\n",
      "Available GPUs: 1\n",
      "Torch device: cuda\n"
     ]
    }
   ],
   "source": [
    "print('Python version: {}'. format(sys.version))\n",
    "print('SciPy version: {}'. format(sp.__version__)) \n",
    "print('NumPy version: {}'. format(np.__version__))\n",
    "print('scikit-learn version: {}'. format(sklearn.__version__))\n",
    "print('pandas version: {}'. format(pd.__version__))\n",
    "print('matplotlib version: {}'. format(matplotlib.__version__))\n",
    "print('IPython version: {}'. format(IPython.__version__)) \n",
    "print('OpenCV version: {}'. format(cv2.__version__)) \n",
    "print('Torch version: {}'. format(torch.__version__))\n",
    "print('Available GPUs: {}'.format(torch.cuda.device_count()))\n",
    "if torch.cuda.is_available:\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "print(\"Torch device: {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    " SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_collate(batch):\n",
    "    batch_size = len(batch)\n",
    "    images = np.array([x[0] for x in batch])\n",
    "    images = torch.from_numpy(images)\n",
    "    \n",
    "    labels = np.array([x[1] for x in batch])\n",
    "    labels = torch.from_numpy(labels)\n",
    "    labels = labels.unsqueeze(1)\n",
    "\n",
    "    assert(images.shape[0] == labels.shape[0] == batch_size)\n",
    "    \n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHESTXRAYS_PATH = Path('./input/chestxrays')\n",
    "class ChestXRaysDataset(Dataset):\n",
    "    def __init__(self, size=128, augment=None):\n",
    "        super(ChestXRaysDataset, self).__init__()\n",
    "        print('ChestXRaysDataset initialized with size={}, augment={}'.format(size, augment))\n",
    "        print('Dataset is located in {}'.format(CHESTXRAYS_PATH))\n",
    "        self.size = size\n",
    "        self.augment = augment\n",
    "        \n",
    "        train_dir = CHESTXRAYS_PATH / 'train'\n",
    "        val_dir = CHESTXRAYS_PATH / 'val'\n",
    "        test_dir = CHESTXRAYS_PATH / 'test'\n",
    "        \n",
    "        normal_cases = []\n",
    "        pneumonia_cases = []\n",
    "        for folder in [train_dir, val_dir, test_dir]:\n",
    "            normal_cases.extend((folder / 'NORMAL').glob('*.jpeg'))\n",
    "            pneumonia_cases.extend((folder / 'PNEUMONIA').glob('*.jpeg'))\n",
    "            \n",
    "        self.labels = np.concatenate((\n",
    "            np.zeros(len(normal_cases)),\n",
    "            np.ones(len(pneumonia_cases))\n",
    "        )).reshape(-1, 1)\n",
    "        self.images = np.concatenate((normal_cases, pneumonia_cases)).reshape(-1, 1)\n",
    "        \n",
    "        self.df = pd.DataFrame(np.concatenate((self.images, self.labels), axis=1), columns=['image', 'label'])\n",
    "        \n",
    "        del self.images\n",
    "\n",
    "        print(\"Dataset: {}\".format(self.df))\n",
    "            \n",
    "\n",
    "    @staticmethod\n",
    "    def _load_image(path, size):\n",
    "        img = Image.open(path)\n",
    "        img = cv2.resize(np.array(img), (size, size), interpolation=cv2.INTER_AREA)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            img = np.dstack([img, img, img])\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # size, size, chan -> chan, size, size\n",
    "        img = np.transpose(img, axes=[2, 0, 1])\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img = self._load_image(row['image'], self.size)\n",
    "        label = row['label']        \n",
    "\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "COVID19_PATH = Path('./input/covid-chestxray-dataset')\n",
    "class COVID19Dataset(Dataset):\n",
    "    def __init__(self, size=128, augment=None):\n",
    "        super(ChestXRaysDataset, self).__init__()\n",
    "        print('COVID19Dataset initialized with size={}, augment={}'.format(size, augment))\n",
    "        print('Dataset is located in {}'.format(COVID19_PATH))\n",
    "        self.size = size\n",
    "        self.augment = augment\n",
    "        \n",
    "        train_dir = CHESTXRAYS_PATH / 'train'\n",
    "        val_dir = CHESTXRAYS_PATH / 'val'\n",
    "        test_dir = CHESTXRAYS_PATH / 'test'\n",
    "        \n",
    "        normal_cases = []\n",
    "        pneumonia_cases = []\n",
    "        for folder in [train_dir, val_dir, test_dir]:\n",
    "            normal_cases.extend((folder / 'NORMAL').glob('*.jpeg'))\n",
    "            pneumonia_cases.extend((folder / 'PNEUMONIA').glob('*.jpeg'))\n",
    "            \n",
    "        self.labels = np.concatenate((\n",
    "            np.zeros(len(normal_cases)),\n",
    "            np.ones(len(pneumonia_cases))\n",
    "        )).reshape(-1, 1)\n",
    "        self.images = np.concatenate((normal_cases, pneumonia_cases)).reshape(-1, 1)\n",
    "        \n",
    "        self.df = pd.DataFrame(np.concatenate((self.images, self.labels), axis=1), columns=['image', 'label'])\n",
    "        \n",
    "        del self.images\n",
    "\n",
    "        print(\"Dataset: {}\".format(self.df))\n",
    "            \n",
    "\n",
    "    @staticmethod\n",
    "    def _load_image(path, size):\n",
    "        img = Image.open(path)\n",
    "        img = cv2.resize(np.array(img), (size, size), interpolation=cv2.INTER_AREA)\n",
    "        if len(img.shape) == 2:\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            img = np.dstack([img, img, img])\n",
    "        else:\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # size, size, chan -> chan, size, size\n",
    "        img = np.transpose(img, axes=[2, 0, 1])\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        img = self._load_image(row['image'], self.size)\n",
    "        label = row['label']        \n",
    "\n",
    "        if self.augment is not None:\n",
    "            img = self.augment(img)\n",
    "\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes=1, dropout=0.5):\n",
    "        super(Classifier, self).__init__()\n",
    "        resnet = resnet34(pretrained=True)\n",
    "        \n",
    "        self.conv1 = resnet.conv1\n",
    "        self.bn1 = resnet.bn1\n",
    "        self.relu = resnet.relu\n",
    "        self.maxpool = resnet.maxpool\n",
    "        self.layer1 = resnet.layer1\n",
    "        self.layer2 = resnet.layer2\n",
    "        self.layer3 = resnet.layer3\n",
    "        self.layer4 = resnet.layer4\n",
    "        self.avgpool = resnet.avgpool\n",
    "        bottleneck_features = resnet.fc.in_features\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.BatchNorm1d(bottleneck_features),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(bottleneck_features, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # mean = MEAN\n",
    "        # std = STD2\n",
    "        x = x / 255.\n",
    "        # x = torch.cat([\n",
    "        #     (x[:, [0]] - mean[0]) / std[0],\n",
    "        #     (x[:, [1]] - mean[1]) / std[1],\n",
    "        #     (x[:, [2]] - mean[2]) / std[2],\n",
    "        #     (x[:, [3]] - mean[3]) / std[3],\n",
    "        # ], 1)\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accuracy(nn.Module):\n",
    "    def __init__(self, threshold=0.5):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        preds = (y_pred > self.threshold).int()\n",
    "        return (preds == y_true).sum().float() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, classifier, dataset, batch_size):\n",
    "        self.classifier = classifier\n",
    "        self.batch_size = batch_size\n",
    "        self.size = size\n",
    "        print('Trainer started with batch size: {} size: {}'.format(batch_size, size))\n",
    "\n",
    "        self.optimizer = None\n",
    "        self.scheduler = None\n",
    "\n",
    "        self.train_dataset = dataset\n",
    "        self.validation_dataset = dataset\n",
    "        \n",
    "       \n",
    "        self.train_idx, self.validation_idx = train_test_split(\n",
    "            list(range(len(self.train_dataset))),\n",
    "            test_size=0.2,\n",
    "            stratify=self.train_dataset.labels\n",
    "        )\n",
    "\n",
    "        loader_params = dict(\n",
    "            batch_size=batch_size,\n",
    "            num_workers=1,\n",
    "            pin_memory=True,\n",
    "            collate_fn=null_collate\n",
    "        )\n",
    "        self.train_loader = DataLoader(\n",
    "            dataset=self.train_dataset,\n",
    "            sampler=SubsetRandomSampler(self.train_idx),\n",
    "            **loader_params\n",
    "        )\n",
    "        self.validation_loader = DataLoader(\n",
    "            dataset=self.validation_dataset,\n",
    "            sampler=SubsetRandomSampler(self.validation_idx),\n",
    "            **loader_params\n",
    "        )\n",
    "        print('Train set: {}'.format(len(self.train_idx)))\n",
    "        print('Validation set: {}'.format(len(self.validation_idx)))\n",
    "\n",
    "        self.it_per_epoch = math.ceil(len(self.train_idx) / self.batch_size)\n",
    "        print('Training with {} mini-batches per epoch'.format(self.it_per_epoch))\n",
    "\n",
    "        \n",
    "    def run(self, max_epochs=10):\n",
    "        self.classifier = self.classifier.cuda()\n",
    "        model = self.classifier\n",
    "\n",
    "        lr = 0.2\n",
    "        it = 0\n",
    "        epoch = 0\n",
    "        it_save = self.it_per_epoch * 5\n",
    "        it_log = math.ceil(self.it_per_epoch / 5)\n",
    "        it_smooth = self.it_per_epoch\n",
    "        print(\"Logging performance every {} iter, smoothing every: {} iter\".format(it_log, it_smooth))\n",
    "        \n",
    "        self.optimizer = optim.SGD(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, momentum=0.9, weight_decay=0.0001)\n",
    "        self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, 2 * self.it_per_epoch, gamma=0.5)\n",
    "\n",
    "        criterion = nn.BCELoss()\n",
    "        criterion = criterion.cuda()\n",
    "        metrics = [Accuracy(), roc_auc_score]\n",
    "\n",
    "        print(\"{}'\".format(self.optimizer))\n",
    "        print(\"{}'\".format(self.scheduler))\n",
    "        print(\"{}'\".format(criterion))\n",
    "        print(\"{}'\".format(metrics))\n",
    "\n",
    "        train_loss = 0\n",
    "        train_roc = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        print('                    |         VALID        |        TRAIN         |         ')\n",
    "        print(' lr     iter  epoch | loss    roc    acc   | loss    roc    acc   |  time   ')\n",
    "        print('------------------------------------------------------------------------------')\n",
    "\n",
    "        start = timer()\n",
    "        while epoch < max_epochs:\n",
    "            smoothed_train_loss = 0\n",
    "            smoothed_train_roc = 0\n",
    "            smoothed_train_acc = 0\n",
    "            smoothed_sum = 0\n",
    "\n",
    "            for inputs, labels in self.train_loader:\n",
    "                epoch = (it + 1) / self.it_per_epoch\n",
    "                \n",
    "                lr = self.scheduler.get_last_lr()[0]\n",
    "\n",
    "                # checkpoint\n",
    "                if it % it_save == 0 and it != 0:\n",
    "                    self.save(model, self.optimizer, it, epoch)\n",
    "\n",
    "                # training\n",
    "\n",
    "                model.train()\n",
    "                inputs = inputs.cuda().float()\n",
    "                labels = labels.cuda().float()\n",
    "\n",
    "                preds = model(inputs)\n",
    "                loss = criterion(preds, labels)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "                self.optimizer.step()\n",
    "                self.scheduler.step()\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    batch_acc, batch_roc = [i(labels.cpu(), preds.cpu()).item() for i in metrics]\n",
    "\n",
    "                batch_loss = loss.item()\n",
    "                smoothed_train_loss += batch_loss\n",
    "                smoothed_train_roc += batch_roc\n",
    "                smoothed_train_acc += batch_acc\n",
    "                smoothed_sum += 1\n",
    "                if it % it_smooth == 0:\n",
    "                    train_loss = smoothed_train_loss / smoothed_sum\n",
    "                    train_roc = smoothed_train_roc / smoothed_sum\n",
    "                    train_acc = smoothed_train_acc / smoothed_sum\n",
    "                    smoothed_train_loss = 0\n",
    "                    smoothed_train_roc = 0\n",
    "                    smoothed_train_acc = 0\n",
    "                    smoothed_sum = 0\n",
    "\n",
    "                if it % it_log == 0:\n",
    "                    print(\n",
    "                        \"{:5f} {:4d} {:5.1f} |                      | {:0.3f}  {:0.3f}  {:0.3f}  | {:6.2f}\".format(\n",
    "                            lr, it, epoch, batch_loss, batch_roc, batch_acc, timer() - start\n",
    "                        ))\n",
    "\n",
    "                it += 1\n",
    "\n",
    "            # validation\n",
    "            valid_loss, valid_m = self.do_valid(model, criterion, metrics)\n",
    "            valid_acc, valid_roc = valid_m\n",
    "\n",
    "            print(\n",
    "                \"{:5f} {:4d} {:5.1f} | {:0.3f}* {:0.3f}  {:0.3f}  | {:0.3f}* {:0.3f}  {:0.3f}  | {:6.2f}\".format(\n",
    "                    lr, it, epoch, valid_loss, valid_roc, valid_acc, train_loss, train_roc, train_acc, timer() - start\n",
    "                ))\n",
    "\n",
    "            # Data loader end\n",
    "        # Training end\n",
    "\n",
    "        self.save(model, self.optimizer, it, epoch)\n",
    "\n",
    "    def do_valid(self, model, criterion, metrics):\n",
    "        model.eval()\n",
    "        valid_num = 0\n",
    "        losses = []\n",
    "\n",
    "        for inputs, labels in self.validation_loader:\n",
    "            inputs = inputs.cuda().float()\n",
    "            labels = labels.cuda().float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                preds = model(inputs)\n",
    "                loss = criterion(preds, labels)\n",
    "                m = [i(labels.cpu(), preds.cpu()).item() for i in metrics]\n",
    "\n",
    "            valid_num += len(inputs)\n",
    "            losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "        assert (valid_num == len(self.validation_loader.sampler))\n",
    "        loss = np.array(losses).mean()\n",
    "        return loss, m\n",
    "    \n",
    "    def save(self, model, optimizer, iter, epoch):\n",
    "        torch.save(model.state_dict(), \"{}_model.pth\".format(iter))\n",
    "        torch.save({\n",
    "            \"optimizer\": optimizer.state_dict(),\n",
    "            \"iter\": iter,\n",
    "            \"epoch\": epoch\n",
    "        }, \"{}_optimizer.pth\".format(iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "size = 256\n",
    "classifier = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChestXRaysDataset initialized with size=256, augment=None\n",
      "Dataset is located in input/chestxrays\n",
      "Dataset:                                                   image label\n",
      "0       input/chestxrays/train/NORMAL/IM-0728-0001.jpeg     0\n",
      "1     input/chestxrays/train/NORMAL/NORMAL2-IM-0698-...     0\n",
      "2     input/chestxrays/train/NORMAL/NORMAL2-IM-0585-...     0\n",
      "3     input/chestxrays/train/NORMAL/NORMAL2-IM-1302-...     0\n",
      "4     input/chestxrays/train/NORMAL/IM-0656-0001-000...     0\n",
      "...                                                 ...   ...\n",
      "5851  input/chestxrays/test/PNEUMONIA/person1680_vir...     1\n",
      "5852  input/chestxrays/test/PNEUMONIA/person1_virus_...     1\n",
      "5853  input/chestxrays/test/PNEUMONIA/person83_bacte...     1\n",
      "5854  input/chestxrays/test/PNEUMONIA/person43_virus...     1\n",
      "5855  input/chestxrays/test/PNEUMONIA/person133_bact...     1\n",
      "\n",
      "[5856 rows x 2 columns]\n",
      "Trainer started with batch size: 64 size: 256\n",
      "Train set: 4684\n",
      "Validation set: 1172\n",
      "Training with 74 mini-batches per epoch\n",
      "Logging performance every 15 iter, smoothing every: 74 iter\n",
      "SGD (\n",
      "Parameter Group 0\n",
      "    dampening: 0\n",
      "    initial_lr: 0.2\n",
      "    lr: 0.2\n",
      "    momentum: 0.9\n",
      "    nesterov: False\n",
      "    weight_decay: 0.0001\n",
      ")'\n",
      "<torch.optim.lr_scheduler.StepLR object at 0x7fb9afdaef10>'\n",
      "BCELoss()'\n",
      "[Accuracy(), <function roc_auc_score at 0x7fb992afd790>]'\n",
      "                    |         VALID        |        TRAIN         |         \n",
      " lr     iter  epoch | loss    roc    acc   | loss    roc    acc   |  time   \n",
      "------------------------------------------------------------------------------\n",
      "0.200000    0   0.0 |                      | 0.892  0.332  0.391  |   1.21\n",
      "0.200000   15   0.2 |                      | 0.273  0.974  0.906  |  11.42\n",
      "0.200000   30   0.4 |                      | 0.260  0.924  0.922  |  21.42\n",
      "0.200000   45   0.6 |                      | 0.076  0.997  0.984  |  31.33\n",
      "0.200000   60   0.8 |                      | 0.288  0.983  0.875  |  41.31\n",
      "0.200000   74   1.0 | 18.661* 0.956  0.500  | 0.892* 0.332  0.391  |  61.45\n",
      "0.200000   75   1.0 |                      | 0.038  0.999  0.984  |  63.31\n",
      "0.200000   90   1.2 |                      | 0.091  0.995  0.953  |  73.21\n",
      "0.200000  105   1.4 |                      | 0.344  0.994  0.922  |  83.43\n",
      "0.200000  120   1.6 |                      | 0.149  0.992  0.906  |  93.16\n",
      "0.200000  135   1.8 |                      | 0.191  0.994  0.906  | 103.36\n",
      "0.200000  148   2.0 | 0.266* 0.979  0.900  | 0.382* 0.966  0.922  | 123.85\n",
      "0.100000  150   2.0 |                      | 0.206  0.986  0.922  | 126.45\n",
      "0.100000  165   2.2 |                      | 0.112  0.994  0.953  | 136.51\n",
      "0.100000  180   2.4 |                      | 0.124  0.996  0.938  | 146.64\n",
      "0.100000  195   2.6 |                      | 0.074  0.995  0.938  | 156.49\n",
      "0.100000  210   2.9 |                      | 0.315  0.962  0.938  | 166.92\n",
      "0.100000  222   3.0 | 0.104* 1.000  1.000  | 0.284* 0.945  0.938  | 187.10\n",
      "0.100000  225   3.1 |                      | 0.160  0.997  0.969  | 190.57\n",
      "0.100000  240   3.3 |                      | 0.212  0.989  0.922  | 200.79\n",
      "0.100000  255   3.5 |                      | 0.220  0.952  0.938  | 210.95\n",
      "0.100000  270   3.7 |                      | 0.201  0.993  0.938  | 220.98\n",
      "0.100000  285   3.9 |                      | 0.042  1.000  0.984  | 231.44\n",
      "0.100000  296   4.0 | 0.122* 1.000  0.900  | 0.045* 1.000  0.984  | 250.47\n",
      "0.050000  300   4.1 |                      | 0.049  0.999  0.984  | 254.40\n",
      "0.050000  315   4.3 |                      | 0.036  0.999  0.984  | 264.57\n",
      "0.050000  330   4.5 |                      | 0.054  0.997  0.969  | 274.43\n",
      "0.050000  345   4.7 |                      | 0.079  0.994  0.984  | 284.11\n",
      "0.050000  360   4.9 |                      | 0.063  1.000  0.984  | 294.17\n",
      "0.050000  370   5.0 | 0.090* 0.987  0.950  | 0.112* 0.995  0.953  | 312.52\n",
      "0.050000  375   5.1 |                      | 0.028  1.000  0.984  | 316.79\n",
      "0.050000  390   5.3 |                      | 0.040  1.000  0.969  | 326.58\n",
      "0.050000  405   5.5 |                      | 0.005  1.000  1.000  | 336.75\n",
      "0.050000  420   5.7 |                      | 0.053  0.996  0.984  | 346.89\n",
      "0.050000  435   5.9 |                      | 0.052  1.000  0.984  | 357.17\n",
      "0.050000  444   6.0 | 0.090* 1.000  0.850  | 0.009* 1.000  1.000  | 374.32\n",
      "0.025000  450   6.1 |                      | 0.047  1.000  0.984  | 379.58\n",
      "0.025000  465   6.3 |                      | 0.013  1.000  1.000  | 389.48\n",
      "0.025000  480   6.5 |                      | 0.005  1.000  1.000  | 399.28\n",
      "0.025000  495   6.7 |                      | 0.028  1.000  0.984  | 409.95\n",
      "0.025000  510   6.9 |                      | 0.047  0.999  0.984  | 420.02\n",
      "0.025000  518   7.0 | 0.108* 1.000  1.000  | 0.053* 0.995  0.984  | 436.85\n",
      "0.025000  525   7.1 |                      | 0.004  1.000  1.000  | 443.21\n",
      "0.025000  540   7.3 |                      | 0.002  1.000  1.000  | 452.89\n",
      "0.025000  555   7.5 |                      | 0.004  1.000  1.000  | 462.68\n",
      "0.025000  570   7.7 |                      | 0.095  1.000  0.953  | 473.07\n",
      "0.025000  585   7.9 |                      | 0.018  1.000  1.000  | 483.00\n",
      "0.025000  592   8.0 | 0.144* 1.000  0.950  | 0.128* 1.000  0.938  | 498.38\n",
      "0.012500  600   8.1 |                      | 0.008  1.000  1.000  | 504.62\n",
      "0.012500  615   8.3 |                      | 0.024  1.000  0.984  | 514.68\n",
      "0.012500  630   8.5 |                      | 0.002  1.000  1.000  | 525.32\n",
      "0.012500  645   8.7 |                      | 0.011  1.000  1.000  | 535.69\n",
      "0.012500  660   8.9 |                      | 0.001  1.000  1.000  | 545.70\n",
      "0.012500  666   9.0 | 0.092* 1.000  1.000  | 0.007* 1.000  1.000  | 560.62\n",
      "0.012500  675   9.1 |                      | 0.049  1.000  0.953  | 567.68\n",
      "0.012500  690   9.3 |                      | 0.002  1.000  1.000  | 577.44\n",
      "0.012500  705   9.5 |                      | 0.007  1.000  1.000  | 587.78\n",
      "0.012500  720   9.7 |                      | 0.012  1.000  1.000  | 598.76\n",
      "0.012500  735   9.9 |                      | 0.006  1.000  1.000  | 610.13\n",
      "0.012500  740  10.0 | 0.097* 1.000  1.000  | 0.021* 1.000  1.000  | 625.03\n"
     ]
    }
   ],
   "source": [
    "dataset = ChestXRaysDataset(size)\n",
    "trainer = Trainer(classifier, dataset, batch_size)\n",
    "trainer.run(max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations\n",
    "- http://www.cell.com/cell/fulltext/S0092-8674(18)30154-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
